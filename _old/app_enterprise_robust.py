#!/usr/bin/env python3
"""
Sistema Enterprise Robusto con Checkpoints Avanzados
====================================================

Sistema enterprise con checkpoints automÃ¡ticos y reanudaciÃ³n de entrenamiento.
Permite pausar y reanudar entrenamientos largos sin perder el progreso.

CaracterÃ­sticas:
- Checkpoints automÃ¡ticos cada 10 minutos
- ReanudaciÃ³n de entrenamiento desde cualquier checkpoint
- Entrenamiento incremental con mÃ©tricas de progreso
- Sistema de recuperaciÃ³n ante fallos
- Monitoreo en tiempo real
"""

import asyncio
import os
import sys
import logging
import time
import json
import joblib
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import argparse

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/enterprise_robust.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class RobustCheckpointManager:
    """Gestor de checkpoints robusto"""
    
    def __init__(self, checkpoint_dir: str = 'checkpoints/enterprise'):
        self.checkpoint_dir = Path(checkpoint_dir)
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        self.checkpoint_interval = 600  # 10 minutos
        
    async def save_checkpoint(
        self, 
        model, 
        scaler, 
        X_train, 
        X_test, 
        y_train, 
        y_test,
        training_epochs: int,
        best_metrics: Dict[str, float],
        start_time: float,
        is_final: bool = False,
        is_emergency: bool = False
    ) -> Dict[str, Any]:
        """Guardar checkpoint con informaciÃ³n completa"""
        
        # Guardar modelo y scaler
        model_path = self.checkpoint_dir / 'enterprise_model.pkl'
        scaler_path = self.checkpoint_dir / 'enterprise_scaler.pkl'
        
        joblib.dump(model, model_path)
        joblib.dump(scaler, scaler_path)
        
        # Crear checkpoint
        checkpoint = {
            'timestamp': datetime.now().isoformat(),
            'duration': time.time() - start_time,
            'training_epochs': training_epochs,
            'best_metrics': best_metrics,
            'current_metrics': self._calculate_current_metrics(model, X_test, y_test),
            'model_path': str(model_path),
            'scaler_path': str(scaler_path),
            'data_shape': {
                'X_train': list(X_train.shape),
                'X_test': list(X_test.shape),
                'y_train': list(y_train.shape),
                'y_test': list(y_test.shape)
            },
            'checkpoint_type': 'final' if is_final else 'emergency' if is_emergency else 'automatic',
            'can_resume': True
        }
        
        # Guardar checkpoint
        checkpoint_path = self.checkpoint_dir / f'checkpoint_{int(time.time())}.json'
        with open(checkpoint_path, 'w') as f:
            json.dump(checkpoint, f, indent=2)
        
        logger.info(f"ğŸ’¾ Checkpoint guardado: {checkpoint_path}")
        return checkpoint
    
    def _calculate_current_metrics(self, model, X_test, y_test) -> Dict[str, float]:
        """Calcular mÃ©tricas actuales"""
        try:
            y_pred = model.predict(X_test)
            return {
                'mse': float(mean_squared_error(y_test, y_pred)),
                'mae': float(mean_absolute_error(y_test, y_pred)),
                'r2': float(r2_score(y_test, y_pred))
            }
        except Exception as e:
            logger.warning(f"âš ï¸ Error calculando mÃ©tricas: {e}")
            return {'mse': 0.0, 'mae': 0.0, 'r2': 0.0}
    
    async def load_checkpoint(self, checkpoint_path: str) -> Dict[str, Any]:
        """Cargar checkpoint"""
        try:
            with open(checkpoint_path, 'r') as f:
                checkpoint = json.load(f)
            
            logger.info(f"âœ… Checkpoint cargado: {checkpoint['timestamp']}")
            logger.info(f"ğŸ“Š Epochs previos: {checkpoint.get('training_epochs', 0)}")
            logger.info(f"ğŸ“Š Mejores mÃ©tricas: {checkpoint.get('best_metrics', {})}")
            
            return checkpoint
        except Exception as e:
            logger.error(f"âŒ Error cargando checkpoint: {e}")
            raise
    
    def list_checkpoints(self) -> List[Path]:
        """Listar checkpoints disponibles"""
        checkpoints = list(self.checkpoint_dir.glob('checkpoint_*.json'))
        return sorted(checkpoints, key=lambda x: x.stat().st_mtime, reverse=True)
    
    def get_latest_checkpoint(self) -> Optional[Path]:
        """Obtener checkpoint mÃ¡s reciente"""
        checkpoints = self.list_checkpoints()
        return checkpoints[0] if checkpoints else None

class RobustTrainingEngine:
    """Motor de entrenamiento robusto con checkpoints"""
    
    def __init__(self):
        self.config = self.load_config()
        self.checkpoint_manager = RobustCheckpointManager()
        
    def load_config(self) -> Dict[str, Any]:
        """Cargar configuraciÃ³n"""
        return {
            'training': {
                'duration': 3600,  # 1 hora
                'checkpoint_interval': 600,  # 10 minutos
                'max_epochs': 1000,
                'batch_size': 32,
                'learning_rate': 0.001,
                'test_size': 0.2,
                'random_state': 42
            },
            'model': {
                'n_estimators': 100,
                'max_depth': 10,
                'min_samples_split': 5,
                'min_samples_leaf': 2,
                'random_state': 42
            }
        }
    
    def generate_synthetic_data(self, n_samples: int = 10000) -> pd.DataFrame:
        """Generar datos sintÃ©ticos para entrenamiento"""
        np.random.seed(42)
        
        # Generar datos de trading sintÃ©ticos
        dates = pd.date_range(start='2020-01-01', periods=n_samples, freq='1H')
        
        # Precios base con tendencia
        base_price = 50000
        trend = np.linspace(0, 0.5, n_samples)
        noise = np.random.normal(0, 0.02, n_samples)
        
        # Generar OHLCV
        close_prices = base_price * (1 + trend + noise)
        open_prices = close_prices * (1 + np.random.normal(0, 0.001, n_samples))
        high_prices = np.maximum(open_prices, close_prices) * (1 + np.abs(np.random.normal(0, 0.005, n_samples)))
        low_prices = np.minimum(open_prices, close_prices) * (1 - np.abs(np.random.normal(0, 0.005, n_samples)))
        volumes = np.random.lognormal(10, 1, n_samples)
        
        df = pd.DataFrame({
            'timestamp': dates,
            'open': open_prices,
            'high': high_prices,
            'low': low_prices,
            'close': close_prices,
            'volume': volumes
        })
        
        return df
    
    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Crear caracterÃ­sticas tÃ©cnicas"""
        df = df.copy()
        
        # Indicadores tÃ©cnicos bÃ¡sicos
        df['sma_20'] = df['close'].rolling(window=20).mean()
        df['sma_50'] = df['close'].rolling(window=50).mean()
        df['rsi'] = self._calculate_rsi(df['close'], 14)
        df['bb_upper'], df['bb_middle'], df['bb_lower'] = self._calculate_bollinger_bands(df['close'], 20)
        df['macd'], df['macd_signal'] = self._calculate_macd(df['close'])
        
        # CaracterÃ­sticas de precio
        df['price_change'] = df['close'].pct_change()
        df['high_low_ratio'] = df['high'] / df['low']
        df['volume_sma'] = df['volume'].rolling(window=20).mean()
        df['volume_ratio'] = df['volume'] / df['volume_sma']
        
        # CaracterÃ­sticas de volatilidad
        df['volatility'] = df['price_change'].rolling(window=20).std()
        df['atr'] = self._calculate_atr(df, 14)
        
        # Target: precio futuro
        df['target'] = df['close'].shift(-1)
        
        # Eliminar NaN
        df = df.dropna()
        
        return df
    
    def _calculate_rsi(self, prices: pd.Series, window: int = 14) -> pd.Series:
        """Calcular RSI"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))
    
    def _calculate_bollinger_bands(self, prices: pd.Series, window: int = 20) -> tuple:
        """Calcular Bandas de Bollinger"""
        sma = prices.rolling(window=window).mean()
        std = prices.rolling(window=window).std()
        upper = sma + (std * 2)
        lower = sma - (std * 2)
        return upper, sma, lower
    
    def _calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> tuple:
        """Calcular MACD"""
        ema_fast = prices.ewm(span=fast).mean()
        ema_slow = prices.ewm(span=slow).mean()
        macd = ema_fast - ema_slow
        macd_signal = macd.ewm(span=signal).mean()
        return macd, macd_signal
    
    def _calculate_atr(self, df: pd.DataFrame, window: int = 14) -> pd.Series:
        """Calcular ATR (Average True Range)"""
        high_low = df['high'] - df['low']
        high_close = np.abs(df['high'] - df['close'].shift())
        low_close = np.abs(df['low'] - df['close'].shift())
        true_range = np.maximum(high_low, np.maximum(high_close, low_close))
        return true_range.rolling(window=window).mean()
    
    def create_sequences(self, df: pd.DataFrame, sequence_length: int = 60) -> tuple:
        """Crear secuencias para entrenamiento"""
        # Seleccionar caracterÃ­sticas
        feature_cols = [col for col in df.columns if col not in ['timestamp', 'target']]
        X = df[feature_cols].values
        y = df['target'].values
        
        # Normalizar datos
        scaler = RobustScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Crear secuencias
        X_seq = []
        y_seq = []
        
        for i in range(sequence_length, len(X_scaled)):
            X_seq.append(X_scaled[i-sequence_length:i].flatten())
            y_seq.append(y[i])
        
        X_seq = np.array(X_seq)
        y_seq = np.array(y_seq)
        
        # Verificar datos
        logger.info(f"ğŸ“Š Features shape: {X_seq.shape}")
        logger.info(f"ğŸ“Š Target shape: {y_seq.shape}")
        logger.info(f"ğŸ“Š NaN count: {np.isnan(X_seq).sum()}, Inf count: {np.isinf(X_seq).sum()}")
        
        return X_seq, y_seq, scaler
    
    async def train_model_robust(self, duration: int = 3600, resume_from: str = None) -> Dict[str, Any]:
        """Entrenar modelo con sistema robusto de checkpoints"""
        logger.info(f"ğŸš€ Iniciando entrenamiento robusto de {duration} segundos...")
        
        start_time = time.time()
        checkpoint_interval = self.config['training']['checkpoint_interval']
        last_checkpoint = start_time
        
        # Variables para entrenamiento
        model = None
        scaler = None
        X_train = None
        X_test = None
        y_train = None
        y_test = None
        training_epochs = 0
        best_metrics = {'mse': float('inf'), 'mae': float('inf'), 'r2': -float('inf')}
        
        try:
            # Cargar checkpoint si se especifica
            if resume_from:
                logger.info(f"ğŸ”„ Reanudando desde checkpoint: {resume_from}")
                checkpoint_data = await self.checkpoint_manager.load_checkpoint(resume_from)
                
                # Cargar modelo y scaler
                model = joblib.load(checkpoint_data['model_path'])
                scaler = joblib.load(checkpoint_data['scaler_path'])
                training_epochs = checkpoint_data.get('training_epochs', 0)
                best_metrics = checkpoint_data.get('best_metrics', best_metrics)
                
                logger.info(f"âœ… Checkpoint cargado - Epochs previos: {training_epochs}")
                logger.info(f"ğŸ“Š Mejores mÃ©tricas previas: {best_metrics}")
            else:
                # Generar datos nuevos
                logger.info("ğŸ“Š Generando datos de entrenamiento...")
                df = self.generate_synthetic_data(10000)
                df_features = self.create_features(df)
                
                # Crear secuencias
                X, y, scaler = self.create_sequences(df_features)
                
                # Dividir datos
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, 
                    test_size=self.config['training']['test_size'],
                    random_state=self.config['training']['random_state']
                )
                
                logger.info(f"ğŸ“Š Datos de entrenamiento: {X_train.shape}")
                logger.info(f"ğŸ“Š Datos de prueba: {X_test.shape}")
                
                # Crear modelo inicial
                model = RandomForestRegressor(
                    n_estimators=self.config['model']['n_estimators'],
                    max_depth=self.config['model']['max_depth'],
                    min_samples_split=self.config['model']['min_samples_split'],
                    min_samples_leaf=self.config['model']['min_samples_leaf'],
                    random_state=self.config['model']['random_state'],
                    n_jobs=-1
                )
            
            # Entrenamiento con checkpoints automÃ¡ticos
            logger.info("ğŸ¯ Iniciando entrenamiento con checkpoints automÃ¡ticos...")
            
            while time.time() - start_time < duration:
                current_time = time.time()
                
                # Entrenar modelo (simulamos entrenamiento incremental)
                if training_epochs == 0:
                    logger.info("ğŸŒ± Entrenamiento inicial...")
                    model.fit(X_train, y_train)
                else:
                    logger.info(f"ğŸ”„ Continuando entrenamiento (epoch {training_epochs + 1})...")
                    # Para RandomForest, re-entrenamos con mÃ¡s estimadores
                    # En un sistema real, esto serÃ­a un modelo que soporte entrenamiento incremental
                    model.n_estimators = min(model.n_estimators + 10, 500)
                    model.fit(X_train, y_train)
                
                training_epochs += 1
                
                # Evaluar modelo
                y_pred = model.predict(X_test)
                mse = mean_squared_error(y_test, y_pred)
                mae = mean_absolute_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)
                
                # Actualizar mejores mÃ©tricas
                if mse < best_metrics['mse']:
                    best_metrics = {'mse': mse, 'mae': mae, 'r2': r2}
                    logger.info(f"ğŸ† Nuevas mejores mÃ©tricas: RÂ²={r2:.4f}")
                
                # Checkpoint automÃ¡tico
                if current_time - last_checkpoint >= checkpoint_interval:
                    await self.checkpoint_manager.save_checkpoint(
                        model, scaler, X_train, X_test, y_train, y_test,
                        training_epochs, best_metrics, start_time
                    )
                    last_checkpoint = current_time
                    logger.info(f"ğŸ’¾ Checkpoint automÃ¡tico guardado (epoch {training_epochs})")
                
                # Log de progreso
                elapsed = current_time - start_time
                remaining = duration - elapsed
                progress = (elapsed / duration) * 100
                logger.info(f"â±ï¸ Progreso: {progress:.1f}% - Epoch {training_epochs} - RÂ²: {r2:.4f} - Restante: {remaining:.0f}s")
                
                # PequeÃ±a pausa para evitar sobrecarga
                await asyncio.sleep(1)
            
            # Guardar checkpoint final
            final_checkpoint = await self.checkpoint_manager.save_checkpoint(
                model, scaler, X_train, X_test, y_train, y_test,
                training_epochs, best_metrics, start_time, is_final=True
            )
            
            logger.info(f"âœ… Entrenamiento completado!")
            logger.info(f"ğŸ“Š Epochs totales: {training_epochs}")
            logger.info(f"ğŸ“Š Mejor MSE: {best_metrics['mse']:.4f}")
            logger.info(f"ğŸ“Š Mejor MAE: {best_metrics['mae']:.4f}")
            logger.info(f"ğŸ“Š Mejor RÂ²: {best_metrics['r2']:.4f}")
            
            return final_checkpoint
            
        except Exception as e:
            logger.error(f"âŒ Error en entrenamiento: {e}")
            # Guardar checkpoint de emergencia
            if model is not None:
                try:
                    await self.checkpoint_manager.save_checkpoint(
                        model, scaler, X_train, X_test, y_train, y_test,
                        training_epochs, best_metrics, start_time, is_emergency=True
                    )
                    logger.info("ğŸ’¾ Checkpoint de emergencia guardado")
                except Exception as emergency_error:
                    logger.error(f"âŒ Error guardando checkpoint de emergencia: {emergency_error}")
            raise

class RobustEnterpriseBot:
    """Bot enterprise robusto con sistema de checkpoints"""
    
    def __init__(self):
        self.training_engine = RobustTrainingEngine()
        self.checkpoint_manager = RobustCheckpointManager()
    
    async def start_training(self, duration: int = 3600, resume: bool = False):
        """Iniciar entrenamiento robusto"""
        try:
            if resume:
                # Buscar checkpoint mÃ¡s reciente
                latest_checkpoint = self.checkpoint_manager.get_latest_checkpoint()
                if latest_checkpoint:
                    logger.info(f"ğŸ”„ Reanudando desde checkpoint mÃ¡s reciente: {latest_checkpoint}")
                    results = await self.training_engine.train_model_robust(
                        duration, str(latest_checkpoint)
                    )
                else:
                    logger.warning("âŒ No se encontraron checkpoints para reanudar")
                    results = await self.training_engine.train_model_robust(duration)
            else:
                results = await self.training_engine.train_model_robust(duration)
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ Error en entrenamiento: {e}")
            raise
    
    def list_checkpoints(self):
        """Listar checkpoints disponibles"""
        checkpoints = self.checkpoint_manager.list_checkpoints()
        
        if not checkpoints:
            print("âŒ No se encontraron checkpoints")
            return
        
        print("\nğŸ“‹ CHECKPOINTS DISPONIBLES:")
        for i, checkpoint in enumerate(checkpoints):
            try:
                with open(checkpoint, 'r') as f:
                    data = json.load(f)
                print(f"{i+1}. {data['timestamp']} - Epochs: {data.get('training_epochs', 0)} - RÂ²: {data.get('best_metrics', {}).get('r2', 0):.4f}")
            except Exception as e:
                print(f"{i+1}. {checkpoint.name} - Error: {e}")
    
    async def resume_from_checkpoint(self, checkpoint_index: int):
        """Reanudar desde checkpoint especÃ­fico"""
        checkpoints = self.checkpoint_manager.list_checkpoints()
        
        if not checkpoints or checkpoint_index >= len(checkpoints):
            logger.error("âŒ Checkpoint no vÃ¡lido")
            return
        
        selected_checkpoint = checkpoints[checkpoint_index]
        logger.info(f"ğŸ”„ Reanudando desde: {selected_checkpoint}")
        
        # Continuar entrenamiento
        results = await self.training_engine.train_model_robust(
            3600, str(selected_checkpoint)
        )
        
        return results

async def main():
    """FunciÃ³n principal"""
    parser = argparse.ArgumentParser(description='Sistema Enterprise Robusto')
    parser.add_argument('--mode', choices=['train', 'resume', 'list'], default='train')
    parser.add_argument('--duration', type=int, default=3600, help='DuraciÃ³n en segundos')
    parser.add_argument('--checkpoint', type=int, help='Ãndice del checkpoint para reanudar')
    
    args = parser.parse_args()
    
    # Crear directorios necesarios
    os.makedirs('logs', exist_ok=True)
    os.makedirs('checkpoints/enterprise', exist_ok=True)
    
    bot = RobustEnterpriseBot()
    
    try:
        if args.mode == 'train':
            logger.info("ğŸš€ Iniciando entrenamiento robusto...")
            results = await bot.start_training(args.duration)
            print(f"âœ… Entrenamiento completado: {results['best_metrics']}")
            
        elif args.mode == 'resume':
            if args.checkpoint is not None:
                logger.info(f"ğŸ”„ Reanudando desde checkpoint {args.checkpoint}...")
                results = await bot.resume_from_checkpoint(args.checkpoint)
                print(f"âœ… Entrenamiento reanudado: {results['best_metrics']}")
            else:
                logger.info("ğŸ”„ Reanudando desde checkpoint mÃ¡s reciente...")
                results = await bot.start_training(args.duration, resume=True)
                print(f"âœ… Entrenamiento reanudado: {results['best_metrics']}")
                
        elif args.mode == 'list':
            bot.list_checkpoints()
            
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ Entrenamiento interrumpido por usuario")
    except Exception as e:
        logger.error(f"âŒ Error: {e}")

if __name__ == "__main__":
    asyncio.run(main())
