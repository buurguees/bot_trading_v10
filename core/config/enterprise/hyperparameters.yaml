# Ruta: core/config/enterprise/hyperparameters.yaml
# hyperparameters.yaml - Configuración de optimización de hiperparámetros
# Ubicación: C:\TradingBot_v10\config\enterprise\hyperparameters.yaml

version: "1.0"

# Configuración global de optimización
optimization:
  # Framework de optimización
  framework: "optuna"  # optuna, hyperopt, ray_tune
  
  # Configuración del estudio
  study:
    study_name: "trading_bot_hyperparameter_optimization"
    direction: "maximize"  # minimize, maximize
    storage: "sqlite:///mlflow/optuna_study.db"
    
  # Configuración de sampling
  sampler:
    name: "TPESampler"  # TPESampler, RandomSampler, CmaEsSampler
    n_startup_trials: 10
    n_ei_candidates: 24
    
  # Configuración de pruning
  pruner:
    name: "MedianPruner"  # MedianPruner, SuccessiveHalvingPruner
    n_startup_trials: 5
    n_warmup_steps: 30
    interval_steps: 10
    
  # Límites de optimización
  limits:
    n_trials: 100
    timeout: 28800  # 8 horas en segundos
    max_concurrent_trials: 4
    
# Espacios de búsqueda por modelo
search_spaces:
  # Espacio para LSTM con Attention
  lstm_attention:
    # Arquitectura
    architecture:
      hidden_size:
        type: "categorical"
        choices: [64, 128, 256, 512]
        
      num_lstm_layers:
        type: "int"
        low: 1
        high: 4
        
      lstm_dropout:
        type: "float"
        low: 0.0
        high: 0.5
        step: 0.1
        
      attention_heads:
        type: "categorical"
        choices: [4, 8, 16]
        
      dense_hidden_size:
        type: "categorical"
        choices: [32, 64, 128]
        
    # Optimización
    optimization:
      learning_rate:
        type: "loguniform"
        low: 1e-5
        high: 1e-2
        
      optimizer:
        type: "categorical"
        choices: ["adam", "adamw", "rmsprop"]
        
      weight_decay:
        type: "loguniform"
        low: 1e-6
        high: 1e-2
        
      batch_size:
        type: "categorical"
        choices: [32, 64, 128, 256]
        
    # Regularización
    regularization:
      dropout_rate:
        type: "float"
        low: 0.1
        high: 0.5
        
      label_smoothing:
        type: "float"
        low: 0.0
        high: 0.2
        
    # Data augmentation
    data_augmentation:
      noise_std:
        type: "float"
        low: 0.001
        high: 0.05
        
      augmentation_prob:
        type: "float"
        low: 0.1
        high: 0.5

  # Espacio para Transformer
  transformer:
    architecture:
      d_model:
        type: "categorical"
        choices: [128, 256, 512]
        
      nhead:
        type: "categorical"
        choices: [4, 8, 16]
        
      num_encoder_layers:
        type: "int"
        low: 2
        high: 8
        
      dim_feedforward:
        type: "categorical"
        choices: [512, 1024, 2048]
        
      dropout:
        type: "float"
        low: 0.05
        high: 0.3
        
    optimization:
      learning_rate:
        type: "loguniform"
        low: 1e-5
        high: 1e-2
        
      warmup_steps:
        type: "int"
        low: 1000
        high: 8000
        
      batch_size:
        type: "categorical"
        choices: [16, 32, 64, 128]

  # Espacio para CNN-LSTM
  cnn_lstm:
    architecture:
      cnn_channels:
        type: "categorical"
        choices: [[32, 64], [64, 128], [128, 256]]
        
      kernel_size:
        type: "categorical"
        choices: [3, 5, 7]
        
      lstm_hidden_size:
        type: "categorical"
        choices: [128, 256, 512]
        
      lstm_layers:
        type: "int"
        low: 1
        high: 3
        
    optimization:
      learning_rate:
        type: "loguniform"
        low: 1e-5
        high: 1e-2
        
      batch_size:
        type: "categorical"
        choices: [32, 64, 128]

# Configuración de objetivos de optimización
objectives:
  # Objetivo principal
  primary:
    name: "val_accuracy"
    direction: "maximize"
    weight: 1.0
    
  # Objetivos secundarios (multi-objective)
  secondary:
    - name: "val_f1_score"
      direction: "maximize"
      weight: 0.8
      
    - name: "model_size_mb"
      direction: "minimize"
      weight: 0.2
      
    - name: "inference_time_ms"
      direction: "minimize"
      weight: 0.3
      
    - name: "training_time_hours"
      direction: "minimize"
      weight: 0.1

# Configuración de early stopping para trials
trial_early_stopping:
  enabled: true
  
  # Criterios de parada temprana
  criteria:
    - metric: "val_loss"
      patience: 20
      min_delta: 0.001
      mode: "min"
      
    - metric: "val_accuracy"
      patience: 30
      min_delta: 0.001
      mode: "max"

# Configuración de validación cruzada
cross_validation:
  enabled: false  # Solo para estudios intensivos
  
  # Configuración de CV
  cv_config:
    n_splits: 5
    strategy: "time_series"  # time_series, stratified
    gap: 10  # Gap entre train y val para time series
    
  # Métricas a promediar
  cv_metrics:
    - "accuracy"
    - "f1_score"
    - "precision"
    - "recall"

# Configuración de ensemble optimization
ensemble_optimization:
  enabled: true
  
  # Métodos de ensemble a probar
  ensemble_methods:
    - name: "weighted_average"
      weights_space:
        type: "dirichlet"
        alpha: [1.0, 1.0, 1.0]  # Para 3 modelos
        
    - name: "voting"
      voting_type:
        type: "categorical"
        choices: ["hard", "soft"]
        
    - name: "stacking"
      meta_learner:
        type: "categorical"
        choices: ["logistic_regression", "random_forest", "neural_network"]

# Configuración de feature selection
feature_optimization:
  enabled: true
  
  # Métodos de selección de features
  selection_methods:
    - name: "recursive_feature_elimination"
      n_features_range:
        type: "int"
        low: 20
        high: 100
        
    - name: "mutual_info"
      k_best_range:
        type: "int"
        low: 15
        high: 80
        
    - name: "lasso_selection"
      alpha_range:
        type: "loguniform"
        low: 1e-4
        high: 1e-1

# Configuración de data preprocessing optimization
preprocessing_optimization:
  enabled: true
  
  # Normalization methods
  normalization:
    method:
      type: "categorical"
      choices: ["standard", "minmax", "robust", "quantile"]
      
  # Feature engineering
  feature_engineering:
    polynomial_degree:
      type: "int"
      low: 1
      high: 3
      
    lag_features:
      type: "categorical"
      choices: [[1, 2, 3], [1, 2, 3, 5], [1, 3, 5, 10]]
      
    rolling_windows:
      type: "categorical"
      choices: [[5, 10], [5, 10, 20], [10, 20, 50]]

# Configuración de métricas personalizadas
custom_metrics:
  # Métricas financieras
  financial_metrics:
    - name: "sharpe_ratio"
      enabled: true
      risk_free_rate: 0.02
      
    - name: "max_drawdown"
      enabled: true
      
    - name: "profit_factor"
      enabled: true
      
    - name: "win_rate"
      enabled: true
      
  # Métricas de trading
  trading_metrics:
    - name: "average_trade_return"
      enabled: true
      
    - name: "trades_per_day"
      enabled: true
      
    - name: "hold_time_hours"
      enabled: true

# Configuración de reporting
reporting:
  enabled: true
  
  # Frecuencia de reportes
  frequency:
    trial_report_interval: 10  # Cada 10 trials
    progress_report_interval: 3600  # Cada hora
    
  # Tipos de reportes
  report_types:
    - "optimization_progress"
    - "best_trials_summary"
    - "parameter_importance"
    - "optimization_history"
    - "parallel_coordinate_plot"
    - "slice_plot"
    
  # Configuración de visualización
  visualization:
    save_plots: true
    plot_format: "png"
    plot_dpi: 300
    output_dir: "reports/hyperparameter_optimization"

# Configuración de resuming
resume:
  enabled: true
  
  # Configuración de checkpoint
  checkpoint:
    save_interval: 10  # Cada 10 trials
    checkpoint_dir: "checkpoints/hyperparameter_optimization"
    
  # Recuperación automática
  auto_resume: true
  resume_from_last: true

# Configuración específica por entorno
environment_configs:
  development:
    n_trials: 20
    timeout: 3600  # 1 hora
    max_concurrent_trials: 2
    
  staging:
    n_trials: 50
    timeout: 14400  # 4 horas
    max_concurrent_trials: 3
    
  production:
    n_trials: 200
    timeout: 86400  # 24 horas
    max_concurrent_trials: 8

# Configuración de distributed optimization
distributed:
  enabled: false  # Habilitar para clusters
  
  # Configuración del cluster
  cluster_config:
    n_workers: 4
    worker_resources:
      cpu: 4
      memory_gb: 8
      gpu: 1
      
  # Configuración de Ray Tune (si se usa)
  ray_tune:
    scheduler: "AsyncHyperBandScheduler"
    search_algorithm: "OptunaSearch"
    
# Configuración de database y storage
storage:
  # Base de datos para estudios
  study_storage:
    url: "sqlite:///mlflow/optuna_studies.db"
    heartbeat_interval: 60
    grace_period: 120
    
  # Almacenamiento de artifacts
  artifacts_storage:
    base_path: "mlflow/optimization_artifacts"
    compression: true
    retention_days: 90
